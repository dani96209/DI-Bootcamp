{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFU8vTGtswnk",
        "outputId": "e27d73f1-8660-4808-9e10-ac86e3a04c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status code: 200\n",
            "\n",
            "\n",
            "<!DOCTYPE html>\n",
            "<html\n",
            "  lang=\"en\"\n",
            "  \n",
            "  data-color-mode=\"auto\" data-light-theme=\"light\" data-dark-t\n",
            "Number of topics: 0\n",
            "Topic Titles: []\n",
            "Topic Descriptions: []\n",
            "\n",
            "DataFrame:\n",
            "Empty DataFrame\n",
            "Columns: [Title, Description]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URL of the webpage\n",
        "url = 'https://github.com/topics'\n",
        "\n",
        "# Fetch the HTML content of the page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Print the status code to ensure the request was successful\n",
        "print(f\"Status code: {response.status_code}\")\n",
        "\n",
        "# Check if the response is successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Print the first 100 characters of the HTML content\n",
        "    print(response.text[:100])\n",
        "\n",
        "    # Save the HTML content to a file named 'webpage.html'\n",
        "    with open('webpage.html', 'w', encoding='utf-8') as file:\n",
        "        file.write(response.text)\n",
        "\n",
        "    # Parse the saved HTML content with BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract the titles and descriptions of the topics\n",
        "    topic_titles = []\n",
        "    topic_descriptions = []\n",
        "\n",
        "    # Loop through all topic containers on the page\n",
        "    for topic in soup.find_all('div', class_='col-md-3'):\n",
        "        title = topic.find('p', class_='f3').text.strip()\n",
        "        description = topic.find('p', class_='f5').text.strip() if topic.find('p', class_='f5') else 'No description available'\n",
        "\n",
        "        # Append the extracted data to the respective lists\n",
        "        topic_titles.append(title)\n",
        "        topic_descriptions.append(description)\n",
        "\n",
        "    # Print the length and content of each extracted list\n",
        "    print(f\"Number of topics: {len(topic_titles)}\")\n",
        "    print(f\"Topic Titles: {topic_titles[:5]}\")  # Print the first 5 topic titles for brevity\n",
        "    print(f\"Topic Descriptions: {topic_descriptions[:5]}\")  # Print the first 5 descriptions for brevity\n",
        "\n",
        "    # Create a dictionary to structure the extracted data\n",
        "    topics_dict = {\n",
        "        'Title': topic_titles,\n",
        "        'Description': topic_descriptions\n",
        "    }\n",
        "\n",
        "    # Convert the dictionary into a pandas DataFrame\n",
        "    df = pd.DataFrame(topics_dict)\n",
        "\n",
        "    # Print the DataFrame to confirm its structure and contents\n",
        "    print(\"\\nDataFrame:\")\n",
        "    print(df)\n",
        "else:\n",
        "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL of the webpage\n",
        "url = 'https://github.com/topics'\n",
        "\n",
        "# Fetch the HTML content of the page\n",
        "response = requests.get(url)\n",
        "\n",
        "# Print the status code to ensure the request was successful\n",
        "print(f\"Status code: {response.status_code}\")\n",
        "\n",
        "# Check if the response is successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the saved HTML content with BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Print out the first 500 characters of the parsed HTML to inspect\n",
        "    print(soup.prettify()[:500])  # Printing the first 500 characters of the parsed HTML\n",
        "\n",
        "    # Inspect the structure of the page to see how topics are defined\n",
        "    # Find all divs with class 'col-md-3', as topics are usually in these divs\n",
        "    topic_containers = soup.find_all('div', class_='col-md-3')\n",
        "\n",
        "    # If no topics are found in this class, print a message\n",
        "    if not topic_containers:\n",
        "        print(\"No topics found in div with class 'col-md-3'.\")\n",
        "else:\n",
        "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdYnareSt9aY",
        "outputId": "2520cd70-44ce-42f0-b1c1-b76d10341e1c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status code: 200\n",
            "<!DOCTYPE html>\n",
            "<html data-a11y-animated-images=\"system\" data-a11y-link-underlines=\"true\" data-color-mode=\"auto\" data-dark-theme=\"dark\" data-light-theme=\"light\" lang=\"en\">\n",
            " <head>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <link href=\"https://github.githubassets.com\" rel=\"dns-prefetch\"/>\n",
            "  <link href=\"https://avatars.githubusercontent.com\" rel=\"dns-prefetch\"/>\n",
            "  <link href=\"https://github-cloud.s3.amazonaws.com\" rel=\"dns-prefetch\"/>\n",
            "  <link href=\"https://user-images.githubusercontent.com/\" rel=\"dns-prefetch\"/>\n",
            "No topics found in div with class 'col-md-3'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Open the saved HTML file\n",
        "\n",
        "with open('webpage.html', 'r', encoding='utf-8') as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "# Parse HTML Content with BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Show the beginning of the HTML to see its structure\n",
        "\n",
        "print(soup.prettify()[:500])  # Displays the first 500 characters to inspect the content\n",
        "\n",
        "# Example 1: Extract topic titles\n",
        "titles = soup.find_all(['h3', 'h2'])\n",
        "\n",
        "# Example 2: Extract topic descriptions\n",
        "descriptions = soup.find_all('p')  # Remplacez par les balises correctes pour la description\n",
        "\n",
        "# Display extracted information\n",
        "print(f\"Nombre de titres extraits: {len(titles)}\")\n",
        "for title in titles[:5]:  # Limit display to the first 5 titles\n",
        "    print(title.text.strip())\n",
        "\n",
        "print(f\"\\nNombre de descriptions extraites: {len(descriptions)}\")\n",
        "for description in descriptions[:5]:  # Limit display to the first 5 descriptions\n",
        "    print(description.text.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B77xG4Cky0pP",
        "outputId": "ec30d46a-83fb-464f-a836-bbb92c4be277"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html data-a11y-animated-images=\"system\" data-a11y-link-underlines=\"true\" data-color-mode=\"auto\" data-dark-theme=\"dark\" data-light-theme=\"light\" lang=\"en\">\n",
            " <head>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <link href=\"https://github.githubassets.com\" rel=\"dns-prefetch\"/>\n",
            "  <link href=\"https://avatars.githubusercontent.com\" rel=\"dns-prefetch\"/>\n",
            "  <link href=\"https://github-cloud.s3.amazonaws.com\" rel=\"dns-prefetch\"/>\n",
            "  <link href=\"https://user-images.githubusercontent.com/\" rel=\"dns-prefetch\"/>\n",
            "Nombre de titres extraits: 6\n",
            "Navigation Menu\n",
            "Use saved searches to filter your results more quickly\n",
            "All featured topics\n",
            "Popular topics\n",
            "Footer\n",
            "\n",
            "Nombre de descriptions extraites: 69\n",
            "We read every piece of feedback, and take your input very seriously.\n",
            "To see all available qualifiers, see our documentation.\n",
            "Browse popular topics on GitHub.\n",
            "Elixir\n",
            "Elixir is a dynamic, functional language designed for building scalable and maintainable applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Show length and content of extracted track list\n",
        "\n",
        "print(f\"\\nNumber of titles extracted: {len(titles)}\")\n",
        "for idx, title in enumerate(titles, start=1):\n",
        "    print(f\"Title {idx}: {title.text.strip()}\")\n",
        "\n",
        "# Show length and content of extracted description list\n",
        "print(f\"\\nNumber of descriptions extracted: {len(descriptions)}\")\n",
        "for idx, description in enumerate(descriptions, start=1):\n",
        "    print(f\"Description {idx}: {description.text.strip()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIz36Iu8zTGv",
        "outputId": "c19686dd-9cc0-4fc2-c5bc-8d894e6e1f65"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of titles extracted: 6\n",
            "Title 1: Navigation Menu\n",
            "Title 2: Use saved searches to filter your results more quickly\n",
            "Title 3: All featured topics\n",
            "Title 4: Popular topics\n",
            "Title 5: Footer\n",
            "Title 6: Footer navigation\n",
            "\n",
            "Number of descriptions extracted: 69\n",
            "Description 1: We read every piece of feedback, and take your input very seriously.\n",
            "Description 2: To see all available qualifiers, see our documentation.\n",
            "Description 3: Browse popular topics on GitHub.\n",
            "Description 4: Elixir\n",
            "Description 5: Elixir is a dynamic, functional language designed for building scalable and maintainable applications.\n",
            "Description 6: R\n",
            "Description 7: R is a free programming language and software environment for statistical computing and graphics.\n",
            "Description 8: Telegram\n",
            "Description 9: Telegram is a non-profit, cloud-based instant messaging service.\n",
            "Description 10: 3D\n",
            "Description 11: 3D refers to the use of three-dimensional graphics, modeling, and animation in various industries.\n",
            "Description 12: Ajax\n",
            "Description 13: Ajax is a technique for creating interactive web applications.\n",
            "Description 14: Algorithm\n",
            "Description 15: Algorithms are self-contained sequences that carry out a variety of tasks.\n",
            "Description 16: Amp\n",
            "Description 17: Amp is a non-blocking concurrency library for PHP.\n",
            "Description 18: Android\n",
            "Description 19: Android is an operating system built by Google designed for mobile devices.\n",
            "Description 20: Angular\n",
            "Description 21: Angular is an open source web application platform.\n",
            "Description 22: Ansible\n",
            "Description 23: Ansible is a simple and powerful automation engine.\n",
            "Description 24: API\n",
            "Description 25: An API (Application Programming Interface) is a collection of protocols and subroutines for building software.\n",
            "Description 26: Arduino\n",
            "Description 27: Arduino is an open source platform for building electronic devices.\n",
            "Description 28: ASP.NET\n",
            "Description 29: ASP.NET is a web framework for building modern web apps and services.\n",
            "Description 30: Awesome Lists\n",
            "Description 31: An awesome list is a list of awesome things curated by the community.\n",
            "Description 32: Amazon Web Services\n",
            "Description 33: Amazon Web Services provides on-demand cloud computing platforms on a subscription basis.\n",
            "Description 34: Azure\n",
            "Description 35: Azure is a cloud computing service created by Microsoft.\n",
            "Description 36: Babel\n",
            "Description 37: Babel is a compiler for writing next generation JavaScript, today.\n",
            "Description 38: Bash\n",
            "Description 39: Bash is a shell and command language interpreter for the GNU operating system.\n",
            "Description 40: Bitcoin\n",
            "Description 41: Bitcoin is a cryptocurrency developed by Satoshi Nakamoto.\n",
            "Description 42: Bootstrap\n",
            "Description 43: Bootstrap is an HTML, CSS, and JavaScript framework.\n",
            "Description 44: Bot\n",
            "Description 45: A bot is an application that runs automated tasks over the Internet.\n",
            "Description 46: C\n",
            "Description 47: C is a general purpose programming language that first appeared in 1972.\n",
            "Description 48: Chrome\n",
            "Description 49: Chrome is a web browser from the tech company Google.\n",
            "Description 50: Chrome extension\n",
            "Description 51: Chrome extensions enable users to customize the Chrome browsing experience.\n",
            "Description 52: Command-line interface\n",
            "Description 53: A CLI, or command-line interface, is a console that helps users issue commands to a program.\n",
            "Description 54: Clojure\n",
            "Description 55: Clojure is a dynamic, general-purpose programming language.\n",
            "Description 56: Code quality\n",
            "Description 57: Automate your code review with style, quality, security, and testâ€‘coverage checks when you need them.\n",
            "Description 58: Code review\n",
            "Description 59: Ensure your code meets quality standards and ship with confidence.\n",
            "Description 60: Compiler\n",
            "Description 61: Compilers are software that translate higher-level programming languages to lower-level languages (e.g. machine code).\n",
            "Description 62: Continuous integration\n",
            "Description 63: Automatically build and test your code as you push it upstream, preventing bugs from being deployed to production.\n",
            "Description 64: C++\n",
            "Description 65: C++ is a general purpose and object-oriented programming language.\n",
            "Description 66: Cryptocurrency\n",
            "Description 67: A cryptocurrency is a digital currency that uses cryptography.\n",
            "Description 68: Crystal\n",
            "Description 69: Crystal is a self-hosted, general purpose programming language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Example of extracting titles and descriptions\n",
        "titles = soup.find_all(['h3', 'h2'])\n",
        "descriptions = soup.find_all('p')\n",
        "\n",
        "# Ensure both lists have the same length by trimming the longer list\n",
        "min_length = min(len(titles), len(descriptions))\n",
        "\n",
        "# Extracting text\n",
        "titles_list = [title.text.strip() for title in titles[:min_length]]\n",
        "descriptions_list = [description.text.strip() for description in descriptions[:min_length]]\n",
        "\n",
        "# Creating a dictionary\n",
        "data = {\n",
        "    'Title': titles_list,\n",
        "    'Description': descriptions_list\n",
        "}\n",
        "\n",
        "# Converting the dictionary to a pandas DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Displaying the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLAq9j-F8F2q",
        "outputId": "61c39569-982d-400f-90d3-a3453a1ed6a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Title  \\\n",
            "0                                    Navigation Menu   \n",
            "1  Use saved searches to filter your results more...   \n",
            "2                                All featured topics   \n",
            "3                                     Popular topics   \n",
            "4                                             Footer   \n",
            "5                                  Footer navigation   \n",
            "\n",
            "                                         Description  \n",
            "0  We read every piece of feedback, and take your...  \n",
            "1  To see all available qualifiers, see our docum...  \n",
            "2                   Browse popular topics on GitHub.  \n",
            "3                                             Elixir  \n",
            "4  Elixir is a dynamic, functional language desig...  \n",
            "5                                                  R  \n"
          ]
        }
      ]
    }
  ]
}